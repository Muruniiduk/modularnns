{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(actual, preds):\n",
    "    return np.sqrt(np.mean((actual - preds)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10, 4)             0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 10, 4)             144       \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 10, 4)             20        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10, 4)             20        \n",
      "=================================================================\n",
      "Total params: 184\n",
      "Trainable params: 184\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, LSTM, RepeatVector, TimeDistributed, RNN\n",
    "from keras.models import Model\n",
    "from keras.losses import mean_squared_error\n",
    "\n",
    "# This returns a tensor\n",
    "inputs = Input(shape=(10,4,))\n",
    "# inputs = Input(shape=(10,1))\n",
    "\n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "x = LSTM(4, return_sequences=True)(inputs)\n",
    "x = TimeDistributed(Dense(4))(x)\n",
    "\n",
    "predictions = Dense(4, input_shape=(4,1))(x)\n",
    "\n",
    "# This creates a model that includes\n",
    "# the Input layer and three Dense layers\n",
    "model_s = Model(inputs=inputs, outputs=predictions)\n",
    "model_s.compile(loss=mean_squared_error,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model_s.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('sim_data.csv')\n",
    "# a = df.to_numpy()\n",
    "# a = a.reshape((1000,20,4)) #samples x timesteps x features\n",
    "# X = a[:,:10,:]\n",
    "# Y = a[:,10:,:]\n",
    "# model.fit(X, Y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual = a[800:,10:,:]\n",
    "# preds = model_s.predict(a[800:,:10,:])\n",
    "# rmse(actual, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE\n",
    "Seems to be heavily dependent on weight inits\n",
    "\n",
    "    1 LSTM                     - 0.0952401825257493 \n",
    "    1 LSTM time. dist          - 0.04111242438159815\n",
    "    1 LSTM time. dist & dense  - 0.025418274029454426\n",
    "    1 LSTM time. dist & dense2 - 0.1322386908689329"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM w/ bounces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('sim_data_borders.csv')\n",
    "# a = df.to_numpy()\n",
    "# a = a.reshape((1000,20,4)) #samples x timesteps x features\n",
    "# X = a[:800,:10,:]\n",
    "# Y = a[:800,10:,:]\n",
    "# model.fit(X, Y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual = a[800:,10:,:]\n",
    "# preds = model.predict(a[800:,:10,:])\n",
    "# rmse(actual, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 LSTM time. dist & dense - **RMSE: 0.1750833958948078**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bounces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 20        \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(4,))\n",
    "# inputs = Input(shape=(10,1))\n",
    "\n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "x = Dense(4)(inputs)\n",
    "# x = Dense(4)(x)\n",
    "# x = Dense(4)(x)\n",
    "# x = TimeDistributed(Dense(4))(x)\n",
    "\n",
    "predictions = x#Dense(4, input_shape=(4,1))(x)\n",
    "\n",
    "# This creates a model that includes\n",
    "# the Input layer and three Dense layers\n",
    "model_b = Model(inputs=inputs, outputs=predictions)\n",
    "model_b.compile(loss=mean_squared_error,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model_b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "800/800 [==============================] - 2s 3ms/step - loss: 0.7811 - acc: 0.0912\n",
      "Epoch 2/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.7188 - acc: 0.0938\n",
      "Epoch 3/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.6626 - acc: 0.1000\n",
      "Epoch 4/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.6128 - acc: 0.1050\n",
      "Epoch 5/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.5680 - acc: 0.1050\n",
      "Epoch 6/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.5284 - acc: 0.1087\n",
      "Epoch 7/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.4928 - acc: 0.1138\n",
      "Epoch 8/200\n",
      "800/800 [==============================] - 0s 31us/step - loss: 0.4615 - acc: 0.1275\n",
      "Epoch 9/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.4337 - acc: 0.1363\n",
      "Epoch 10/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.4089 - acc: 0.1525\n",
      "Epoch 11/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.3869 - acc: 0.1638\n",
      "Epoch 12/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.3674 - acc: 0.1675\n",
      "Epoch 13/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.3500 - acc: 0.1675\n",
      "Epoch 14/200\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.3345 - acc: 0.1750\n",
      "Epoch 15/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.3208 - acc: 0.1825\n",
      "Epoch 16/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.3082 - acc: 0.1925\n",
      "Epoch 17/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.2971 - acc: 0.2062\n",
      "Epoch 18/200\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.2872 - acc: 0.2213\n",
      "Epoch 19/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.2780 - acc: 0.2475\n",
      "Epoch 20/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.2697 - acc: 0.2650\n",
      "Epoch 21/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.2621 - acc: 0.2888\n",
      "Epoch 22/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.2553 - acc: 0.3075\n",
      "Epoch 23/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.2489 - acc: 0.3238\n",
      "Epoch 24/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.2430 - acc: 0.3412\n",
      "Epoch 25/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.2376 - acc: 0.3550\n",
      "Epoch 26/200\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.2325 - acc: 0.3812\n",
      "Epoch 27/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.2278 - acc: 0.3950\n",
      "Epoch 28/200\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.2235 - acc: 0.4113\n",
      "Epoch 29/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.2194 - acc: 0.4163\n",
      "Epoch 30/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.2153 - acc: 0.4275\n",
      "Epoch 31/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.2116 - acc: 0.4425\n",
      "Epoch 32/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.2082 - acc: 0.4563\n",
      "Epoch 33/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.2049 - acc: 0.4612\n",
      "Epoch 34/200\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.2017 - acc: 0.4750\n",
      "Epoch 35/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.1987 - acc: 0.4800\n",
      "Epoch 36/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.1958 - acc: 0.4900\n",
      "Epoch 37/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.1931 - acc: 0.4975\n",
      "Epoch 38/200\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.1905 - acc: 0.5012\n",
      "Epoch 39/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1880 - acc: 0.5125\n",
      "Epoch 40/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1856 - acc: 0.5150\n",
      "Epoch 41/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1832 - acc: 0.5250\n",
      "Epoch 42/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.1809 - acc: 0.5363\n",
      "Epoch 43/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1788 - acc: 0.5375\n",
      "Epoch 44/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.1766 - acc: 0.5400\n",
      "Epoch 45/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1746 - acc: 0.5450\n",
      "Epoch 46/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1726 - acc: 0.5525\n",
      "Epoch 47/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.1706 - acc: 0.5613\n",
      "Epoch 48/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.1688 - acc: 0.5712\n",
      "Epoch 49/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.1670 - acc: 0.5775\n",
      "Epoch 50/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1651 - acc: 0.5887\n",
      "Epoch 51/200\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.1634 - acc: 0.5975\n",
      "Epoch 52/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1617 - acc: 0.6062\n",
      "Epoch 53/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1601 - acc: 0.6112\n",
      "Epoch 54/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1584 - acc: 0.6212\n",
      "Epoch 55/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.1568 - acc: 0.6225\n",
      "Epoch 56/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1553 - acc: 0.6313\n",
      "Epoch 57/200\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.1538 - acc: 0.6375\n",
      "Epoch 58/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1523 - acc: 0.6388\n",
      "Epoch 59/200\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.1508 - acc: 0.6412\n",
      "Epoch 60/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.1495 - acc: 0.6475\n",
      "Epoch 61/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.1480 - acc: 0.6475\n",
      "Epoch 62/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1467 - acc: 0.6512\n",
      "Epoch 63/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.1454 - acc: 0.6562\n",
      "Epoch 64/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.1441 - acc: 0.6600\n",
      "Epoch 65/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.1428 - acc: 0.6638\n",
      "Epoch 66/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.1415 - acc: 0.6663\n",
      "Epoch 67/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.1404 - acc: 0.6687\n",
      "Epoch 68/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1392 - acc: 0.6713\n",
      "Epoch 69/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.1380 - acc: 0.6763\n",
      "Epoch 70/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.1369 - acc: 0.6800\n",
      "Epoch 71/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.1358 - acc: 0.6800\n",
      "Epoch 72/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.1347 - acc: 0.6863\n",
      "Epoch 73/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.1336 - acc: 0.6875\n",
      "Epoch 74/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.1326 - acc: 0.6913\n",
      "Epoch 75/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.1316 - acc: 0.6925\n",
      "Epoch 76/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.1306 - acc: 0.6962\n",
      "Epoch 77/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1296 - acc: 0.6975\n",
      "Epoch 78/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.1287 - acc: 0.6987\n",
      "Epoch 79/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1278 - acc: 0.7025\n",
      "Epoch 80/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.1269 - acc: 0.7025\n",
      "Epoch 81/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.1260 - acc: 0.7037\n",
      "Epoch 82/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1251 - acc: 0.7100\n",
      "Epoch 83/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1243 - acc: 0.7112\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 27us/step - loss: 0.1235 - acc: 0.7137\n",
      "Epoch 85/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.1227 - acc: 0.7125\n",
      "Epoch 86/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1219 - acc: 0.7137\n",
      "Epoch 87/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1212 - acc: 0.7150\n",
      "Epoch 88/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.1204 - acc: 0.7188\n",
      "Epoch 89/200\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.1197 - acc: 0.7200\n",
      "Epoch 90/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.1191 - acc: 0.7188\n",
      "Epoch 91/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1183 - acc: 0.7225\n",
      "Epoch 92/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1177 - acc: 0.7225\n",
      "Epoch 93/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.1171 - acc: 0.7213\n",
      "Epoch 94/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.1164 - acc: 0.7213\n",
      "Epoch 95/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.1158 - acc: 0.7213\n",
      "Epoch 96/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1152 - acc: 0.7238\n",
      "Epoch 97/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1147 - acc: 0.7250\n",
      "Epoch 98/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.1141 - acc: 0.7225\n",
      "Epoch 99/200\n",
      "800/800 [==============================] - 0s 32us/step - loss: 0.1136 - acc: 0.7238\n",
      "Epoch 100/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1130 - acc: 0.7263\n",
      "Epoch 101/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.1125 - acc: 0.7288\n",
      "Epoch 102/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.1120 - acc: 0.7312\n",
      "Epoch 103/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.1116 - acc: 0.7312\n",
      "Epoch 104/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1111 - acc: 0.7312\n",
      "Epoch 105/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.1107 - acc: 0.7312\n",
      "Epoch 106/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.1102 - acc: 0.7300\n",
      "Epoch 107/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.1098 - acc: 0.7312\n",
      "Epoch 108/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.1094 - acc: 0.7325\n",
      "Epoch 109/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1090 - acc: 0.7325\n",
      "Epoch 110/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.1086 - acc: 0.7375\n",
      "Epoch 111/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1082 - acc: 0.7362\n",
      "Epoch 112/200\n",
      "800/800 [==============================] - 0s 31us/step - loss: 0.1078 - acc: 0.7350\n",
      "Epoch 113/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.1075 - acc: 0.7388\n",
      "Epoch 114/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1071 - acc: 0.7400\n",
      "Epoch 115/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.1068 - acc: 0.7388\n",
      "Epoch 116/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.1065 - acc: 0.7413\n",
      "Epoch 117/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1062 - acc: 0.7413\n",
      "Epoch 118/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.1059 - acc: 0.7413\n",
      "Epoch 119/200\n",
      "800/800 [==============================] - 0s 31us/step - loss: 0.1056 - acc: 0.7437\n",
      "Epoch 120/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1053 - acc: 0.7462\n",
      "Epoch 121/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1051 - acc: 0.7475\n",
      "Epoch 122/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.1048 - acc: 0.7488\n",
      "Epoch 123/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.1046 - acc: 0.7475\n",
      "Epoch 124/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1044 - acc: 0.7512\n",
      "Epoch 125/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.1041 - acc: 0.7512\n",
      "Epoch 126/200\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.1039 - acc: 0.7512\n",
      "Epoch 127/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.1037 - acc: 0.7525\n",
      "Epoch 128/200\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.1034 - acc: 0.7525\n",
      "Epoch 129/200\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.1032 - acc: 0.7525\n",
      "Epoch 130/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1030 - acc: 0.7525\n",
      "Epoch 131/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.1029 - acc: 0.7525\n",
      "Epoch 132/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.1027 - acc: 0.7538\n",
      "Epoch 133/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.1025 - acc: 0.7525\n",
      "Epoch 134/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1024 - acc: 0.7563\n",
      "Epoch 135/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.1022 - acc: 0.7538\n",
      "Epoch 136/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1020 - acc: 0.7563\n",
      "Epoch 137/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1019 - acc: 0.7563\n",
      "Epoch 138/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1017 - acc: 0.7587\n",
      "Epoch 139/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.1016 - acc: 0.7587\n",
      "Epoch 140/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.1015 - acc: 0.7612\n",
      "Epoch 141/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1013 - acc: 0.7650\n",
      "Epoch 142/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1012 - acc: 0.7638\n",
      "Epoch 143/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.1011 - acc: 0.7638\n",
      "Epoch 144/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.1010 - acc: 0.7638\n",
      "Epoch 145/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.1009 - acc: 0.7638\n",
      "Epoch 146/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1008 - acc: 0.7662\n",
      "Epoch 147/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1007 - acc: 0.7650\n",
      "Epoch 148/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.1007 - acc: 0.7662\n",
      "Epoch 149/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.1005 - acc: 0.7662\n",
      "Epoch 150/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.1004 - acc: 0.7662\n",
      "Epoch 151/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.1004 - acc: 0.7675\n",
      "Epoch 152/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.1003 - acc: 0.7675\n",
      "Epoch 153/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.1002 - acc: 0.7688\n",
      "Epoch 154/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.1002 - acc: 0.7688\n",
      "Epoch 155/200\n",
      "800/800 [==============================] - 0s 31us/step - loss: 0.1001 - acc: 0.7688\n",
      "Epoch 156/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.1000 - acc: 0.7688\n",
      "Epoch 157/200\n",
      "800/800 [==============================] - 0s 33us/step - loss: 0.0999 - acc: 0.7688\n",
      "Epoch 158/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.0999 - acc: 0.7700\n",
      "Epoch 159/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.0998 - acc: 0.7700\n",
      "Epoch 160/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.0998 - acc: 0.7700\n",
      "Epoch 161/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.0997 - acc: 0.7700\n",
      "Epoch 162/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.0997 - acc: 0.7712\n",
      "Epoch 163/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.0997 - acc: 0.7712\n",
      "Epoch 164/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.0996 - acc: 0.7712\n",
      "Epoch 165/200\n",
      "800/800 [==============================] - 0s 31us/step - loss: 0.0996 - acc: 0.7712\n",
      "Epoch 166/200\n",
      "800/800 [==============================] - 0s 31us/step - loss: 0.0995 - acc: 0.7712\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 27us/step - loss: 0.0995 - acc: 0.7725\n",
      "Epoch 168/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.0994 - acc: 0.7725\n",
      "Epoch 169/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.0994 - acc: 0.7737\n",
      "Epoch 170/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.0994 - acc: 0.7750\n",
      "Epoch 171/200\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.0994 - acc: 0.7750\n",
      "Epoch 172/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.0993 - acc: 0.7725\n",
      "Epoch 173/200\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.0993 - acc: 0.7725\n",
      "Epoch 174/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.0993 - acc: 0.7725\n",
      "Epoch 175/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.0993 - acc: 0.7737\n",
      "Epoch 176/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.0992 - acc: 0.7750\n",
      "Epoch 177/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.0992 - acc: 0.7762\n",
      "Epoch 178/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.0992 - acc: 0.7750\n",
      "Epoch 179/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.0992 - acc: 0.7787\n",
      "Epoch 180/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.0992 - acc: 0.7775\n",
      "Epoch 181/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.0991 - acc: 0.7762\n",
      "Epoch 182/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.0992 - acc: 0.7775\n",
      "Epoch 183/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.0991 - acc: 0.7787\n",
      "Epoch 184/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.0991 - acc: 0.7775\n",
      "Epoch 185/200\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.0991 - acc: 0.7775\n",
      "Epoch 186/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.0991 - acc: 0.7775\n",
      "Epoch 187/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.0991 - acc: 0.7775\n",
      "Epoch 188/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.0991 - acc: 0.7775\n",
      "Epoch 189/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.0991 - acc: 0.7787\n",
      "Epoch 190/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.0991 - acc: 0.7800\n",
      "Epoch 191/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.0990 - acc: 0.7787\n",
      "Epoch 192/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.0991 - acc: 0.7787\n",
      "Epoch 193/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.0990 - acc: 0.7800\n",
      "Epoch 194/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.0990 - acc: 0.7825\n",
      "Epoch 195/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.0990 - acc: 0.7775\n",
      "Epoch 196/200\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.0990 - acc: 0.7825\n",
      "Epoch 197/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.0990 - acc: 0.7825\n",
      "Epoch 198/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.0990 - acc: 0.7812\n",
      "Epoch 199/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.0990 - acc: 0.7812\n",
      "Epoch 200/200\n",
      "800/800 [==============================] - 0s 31us/step - loss: 0.0990 - acc: 0.7825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f70f0431518>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('bounces.csv')\n",
    "a = df.to_numpy()\n",
    "a = a.reshape((1000,2,4)) #samples x timesteps x features\n",
    "train_X = a[:800,0,:]\n",
    "test_X = a[800:,0,:]\n",
    "train_Y = a[:800,1,:]\n",
    "test_Y = a[800:,1,:]\n",
    "model_b.fit(train_X, train_Y, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3273246691471819"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = test_Y\n",
    "preds = model_b.predict(test_X)\n",
    "rmse(actual, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[array([[ 9.9326831e-01, -1.0076046e+00, -6.6981562e-03,  7.6528147e-02],\n",
      "       [ 7.4442578e-03,  3.8747001e-01,  1.3499949e-03, -4.9418807e-02],\n",
      "       [-1.0452822e-03,  5.7089175e-03,  9.6920556e-01, -1.0753642e+00],\n",
      "       [ 4.4454460e-04, -3.9559748e-02,  1.7613469e-02,  3.9777878e-01]],\n",
      "      dtype=float32), array([0.00376057, 0.48957288, 0.02017808, 0.50555724], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "for layer in model_b.layers:\n",
    "    weights = layer.get_weights() # list of numpy arrays\n",
    "    print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 10, 2)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 10, 2)             40        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10, 2)             6         \n",
      "=================================================================\n",
      "Total params: 46\n",
      "Trainable params: 46\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, LSTM, RepeatVector, TimeDistributed, RNN\n",
    "from keras.models import Model\n",
    "from keras.losses import mean_squared_error\n",
    "\n",
    "# This returns a tensor\n",
    "inputs = Input(shape=(10,2,))\n",
    "# inputs = Input(shape=(10,1))\n",
    "\n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "x = LSTM(2, return_sequences=True)(inputs)\n",
    "# x = TimeDistributed(Dense(4))(x)\n",
    "\n",
    "predictions = Dense(2, input_shape=(4,1))(x)\n",
    "\n",
    "# This creates a model that includes\n",
    "# the Input layer and three Dense layers\n",
    "model_ws = Model(inputs=inputs, outputs=predictions)\n",
    "model_ws.compile(loss=mean_squared_error,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model_ws.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "800/800 [==============================] - 1s 745us/step - loss: 0.2325 - acc: 0.1534\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 0s 251us/step - loss: 0.1776 - acc: 0.1445\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 0s 248us/step - loss: 0.1408 - acc: 0.1364\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 0s 252us/step - loss: 0.1180 - acc: 0.1334\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 0s 253us/step - loss: 0.1046 - acc: 0.1355\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 0s 249us/step - loss: 0.0969 - acc: 0.1400\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 0s 252us/step - loss: 0.0918 - acc: 0.1430\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 0s 252us/step - loss: 0.0880 - acc: 0.1469\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 0s 251us/step - loss: 0.0848 - acc: 0.1517\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 0s 247us/step - loss: 0.0819 - acc: 0.1522\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 0s 247us/step - loss: 0.0793 - acc: 0.1590\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 0s 257us/step - loss: 0.0768 - acc: 0.1684\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 0s 259us/step - loss: 0.0745 - acc: 0.1811\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 0s 251us/step - loss: 0.0724 - acc: 0.1959\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 0s 260us/step - loss: 0.0704 - acc: 0.2148\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 0s 262us/step - loss: 0.0686 - acc: 0.2369\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 0s 264us/step - loss: 0.0668 - acc: 0.2601\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 0s 261us/step - loss: 0.0652 - acc: 0.2901\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 0s 252us/step - loss: 0.0636 - acc: 0.3368\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 0s 253us/step - loss: 0.0620 - acc: 0.3945\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 0s 252us/step - loss: 0.0606 - acc: 0.4869\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 0s 266us/step - loss: 0.0592 - acc: 0.5565\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 0s 258us/step - loss: 0.0579 - acc: 0.6137\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 0s 259us/step - loss: 0.0565 - acc: 0.7084\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 0s 249us/step - loss: 0.0552 - acc: 0.7650\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 0s 262us/step - loss: 0.0539 - acc: 0.7961\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 0s 260us/step - loss: 0.0526 - acc: 0.8555\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 0s 257us/step - loss: 0.0513 - acc: 0.8980\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 0s 264us/step - loss: 0.0499 - acc: 0.8969\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 0s 248us/step - loss: 0.0485 - acc: 0.9113\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 0s 253us/step - loss: 0.0470 - acc: 0.9216\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 0s 251us/step - loss: 0.0455 - acc: 0.9178\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 0s 270us/step - loss: 0.0438 - acc: 0.9161\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 0s 262us/step - loss: 0.0420 - acc: 0.9099\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 0s 266us/step - loss: 0.0401 - acc: 0.9096\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 0s 269us/step - loss: 0.0380 - acc: 0.9099\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 0s 250us/step - loss: 0.0357 - acc: 0.9098\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 0s 247us/step - loss: 0.0333 - acc: 0.9092\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 0s 250us/step - loss: 0.0307 - acc: 0.9098\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 0s 245us/step - loss: 0.0280 - acc: 0.9116\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 0s 251us/step - loss: 0.0252 - acc: 0.9131\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 0s 252us/step - loss: 0.0225 - acc: 0.9161\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 0s 249us/step - loss: 0.0200 - acc: 0.9191\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 0s 246us/step - loss: 0.0178 - acc: 0.9190\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 0s 251us/step - loss: 0.0159 - acc: 0.9214\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 0s 251us/step - loss: 0.0146 - acc: 0.9230\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 0s 247us/step - loss: 0.0135 - acc: 0.9234\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 0s 246us/step - loss: 0.0128 - acc: 0.9255\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 0s 250us/step - loss: 0.0123 - acc: 0.9267\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 0s 247us/step - loss: 0.0118 - acc: 0.9272\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 0s 250us/step - loss: 0.0115 - acc: 0.9280\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 0s 249us/step - loss: 0.0112 - acc: 0.9287\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 0s 250us/step - loss: 0.0109 - acc: 0.9299\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 0s 248us/step - loss: 0.0106 - acc: 0.9285\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 0s 250us/step - loss: 0.0104 - acc: 0.9311\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 0s 252us/step - loss: 0.0101 - acc: 0.9312\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 0s 249us/step - loss: 0.0099 - acc: 0.9316\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 0s 246us/step - loss: 0.0097 - acc: 0.9339\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 0s 250us/step - loss: 0.0095 - acc: 0.9335\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 0s 255us/step - loss: 0.0093 - acc: 0.9341\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 0s 251us/step - loss: 0.0091 - acc: 0.9349\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 0s 251us/step - loss: 0.0089 - acc: 0.9354\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 0s 246us/step - loss: 0.0087 - acc: 0.9359\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 0s 253us/step - loss: 0.0085 - acc: 0.9367\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 0s 246us/step - loss: 0.0084 - acc: 0.9379\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 0s 249us/step - loss: 0.0082 - acc: 0.9381\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 0s 246us/step - loss: 0.0080 - acc: 0.9381\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 0s 250us/step - loss: 0.0079 - acc: 0.9379\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 0s 247us/step - loss: 0.0077 - acc: 0.9388\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 0s 248us/step - loss: 0.0076 - acc: 0.9384\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 0s 250us/step - loss: 0.0075 - acc: 0.9394\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 0s 248us/step - loss: 0.0073 - acc: 0.9393\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 0s 247us/step - loss: 0.0072 - acc: 0.9391\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 0s 250us/step - loss: 0.0071 - acc: 0.9395\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 0s 249us/step - loss: 0.0070 - acc: 0.9396\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 0s 251us/step - loss: 0.0069 - acc: 0.9394\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 0s 248us/step - loss: 0.0068 - acc: 0.9390\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 0s 253us/step - loss: 0.0066 - acc: 0.9396\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 0s 250us/step - loss: 0.0065 - acc: 0.9397\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 0s 249us/step - loss: 0.0064 - acc: 0.9397\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 0s 248us/step - loss: 0.0064 - acc: 0.9400\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 0s 248us/step - loss: 0.0063 - acc: 0.9398\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 251us/step - loss: 0.0062 - acc: 0.9399\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 0s 245us/step - loss: 0.0061 - acc: 0.9404\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 0s 251us/step - loss: 0.0060 - acc: 0.9403\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 0s 246us/step - loss: 0.0059 - acc: 0.9402\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 0s 247us/step - loss: 0.0059 - acc: 0.9406\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 0s 246us/step - loss: 0.0058 - acc: 0.9401\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 0s 242us/step - loss: 0.0057 - acc: 0.9408\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 0s 249us/step - loss: 0.0056 - acc: 0.9411\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 0s 248us/step - loss: 0.0056 - acc: 0.9409\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 0s 247us/step - loss: 0.0055 - acc: 0.9406\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 0s 247us/step - loss: 0.0055 - acc: 0.9408\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 0s 243us/step - loss: 0.0054 - acc: 0.9406\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 0s 247us/step - loss: 0.0053 - acc: 0.9409\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 0s 250us/step - loss: 0.0053 - acc: 0.9409\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 0s 244us/step - loss: 0.0052 - acc: 0.9402\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 0s 245us/step - loss: 0.0052 - acc: 0.9409\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 0s 243us/step - loss: 0.0051 - acc: 0.9407\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 0s 244us/step - loss: 0.0051 - acc: 0.9410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f70f02c04a8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sim_data.csv')\n",
    "a = df.to_numpy()\n",
    "a = a.reshape((1000,20,4)) #samples x timesteps x features\n",
    "a = np.delete(a, [1,3], axis=2)\n",
    "X = a[:800,:10,:]\n",
    "Y = a[:800,10:,:]\n",
    "model_ws.fit(X, Y, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 6         \n",
      "=================================================================\n",
      "Total params: 6\n",
      "Trainable params: 6\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "800/800 [==============================] - 0s 191us/step - loss: 0.6157 - acc: 0.1425\n",
      "Epoch 2/200\n",
      "800/800 [==============================] - 0s 31us/step - loss: 0.5579 - acc: 0.1425\n",
      "Epoch 3/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.5070 - acc: 0.1425\n",
      "Epoch 4/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.4624 - acc: 0.1400\n",
      "Epoch 5/200\n",
      "800/800 [==============================] - 0s 31us/step - loss: 0.4235 - acc: 0.1363\n",
      "Epoch 6/200\n",
      "800/800 [==============================] - 0s 32us/step - loss: 0.3894 - acc: 0.1338\n",
      "Epoch 7/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.3599 - acc: 0.1325\n",
      "Epoch 8/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.3336 - acc: 0.1263\n",
      "Epoch 9/200\n",
      "800/800 [==============================] - 0s 35us/step - loss: 0.3107 - acc: 0.1225\n",
      "Epoch 10/200\n",
      "800/800 [==============================] - 0s 32us/step - loss: 0.2903 - acc: 0.1113\n",
      "Epoch 11/200\n",
      "800/800 [==============================] - 0s 32us/step - loss: 0.2723 - acc: 0.1063\n",
      "Epoch 12/200\n",
      "800/800 [==============================] - 0s 34us/step - loss: 0.2561 - acc: 0.0987\n",
      "Epoch 13/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.2418 - acc: 0.0925\n",
      "Epoch 14/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.2289 - acc: 0.0863\n",
      "Epoch 15/200\n",
      "800/800 [==============================] - 0s 32us/step - loss: 0.2172 - acc: 0.0838\n",
      "Epoch 16/200\n",
      "800/800 [==============================] - 0s 31us/step - loss: 0.2066 - acc: 0.0825\n",
      "Epoch 17/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.1971 - acc: 0.0850\n",
      "Epoch 18/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.1882 - acc: 0.0762\n",
      "Epoch 19/200\n",
      "800/800 [==============================] - 0s 32us/step - loss: 0.1801 - acc: 0.0688\n",
      "Epoch 20/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.1725 - acc: 0.0600\n",
      "Epoch 21/200\n",
      "800/800 [==============================] - 0s 32us/step - loss: 0.1655 - acc: 0.0513\n",
      "Epoch 22/200\n",
      "800/800 [==============================] - 0s 32us/step - loss: 0.1588 - acc: 0.0437\n",
      "Epoch 23/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.1526 - acc: 0.0312\n",
      "Epoch 24/200\n",
      "800/800 [==============================] - 0s 33us/step - loss: 0.1467 - acc: 0.0238\n",
      "Epoch 25/200\n",
      "800/800 [==============================] - 0s 36us/step - loss: 0.1410 - acc: 0.0588\n",
      "Epoch 26/200\n",
      "800/800 [==============================] - 0s 32us/step - loss: 0.1356 - acc: 0.0938\n",
      "Epoch 27/200\n",
      "800/800 [==============================] - 0s 35us/step - loss: 0.1305 - acc: 0.1387\n",
      "Epoch 28/200\n",
      "800/800 [==============================] - 0s 32us/step - loss: 0.1255 - acc: 0.3038\n",
      "Epoch 29/200\n",
      "800/800 [==============================] - 0s 31us/step - loss: 0.1208 - acc: 0.5475\n",
      "Epoch 30/200\n",
      "800/800 [==============================] - 0s 32us/step - loss: 0.1162 - acc: 0.7612\n",
      "Epoch 31/200\n",
      "800/800 [==============================] - 0s 33us/step - loss: 0.1119 - acc: 0.8400\n",
      "Epoch 32/200\n",
      "800/800 [==============================] - 0s 32us/step - loss: 0.1076 - acc: 0.8738\n",
      "Epoch 33/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.1035 - acc: 0.8975\n",
      "Epoch 34/200\n",
      "800/800 [==============================] - 0s 32us/step - loss: 0.0996 - acc: 0.9012\n",
      "Epoch 35/200\n",
      "800/800 [==============================] - 0s 32us/step - loss: 0.0958 - acc: 0.9062\n",
      "Epoch 36/200\n",
      "800/800 [==============================] - 0s 32us/step - loss: 0.0922 - acc: 0.9100\n",
      "Epoch 37/200\n",
      "800/800 [==============================] - 0s 31us/step - loss: 0.0886 - acc: 0.9163\n",
      "Epoch 38/200\n",
      "800/800 [==============================] - 0s 31us/step - loss: 0.0853 - acc: 0.9213\n",
      "Epoch 39/200\n",
      "800/800 [==============================] - 0s 34us/step - loss: 0.0820 - acc: 0.9225\n",
      "Epoch 40/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.0788 - acc: 0.9275\n",
      "Epoch 41/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.0758 - acc: 0.9275\n",
      "Epoch 42/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.0728 - acc: 0.9325\n",
      "Epoch 43/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.0700 - acc: 0.9350\n",
      "Epoch 44/200\n",
      "800/800 [==============================] - 0s 39us/step - loss: 0.0673 - acc: 0.9387\n",
      "Epoch 45/200\n",
      "800/800 [==============================] - 0s 31us/step - loss: 0.0647 - acc: 0.9387\n",
      "Epoch 46/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.0621 - acc: 0.9413\n",
      "Epoch 47/200\n",
      "800/800 [==============================] - 0s 33us/step - loss: 0.0597 - acc: 0.9413\n",
      "Epoch 48/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.0573 - acc: 0.9462\n",
      "Epoch 49/200\n",
      "800/800 [==============================] - 0s 32us/step - loss: 0.0550 - acc: 0.9462\n",
      "Epoch 50/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.0529 - acc: 0.9462\n",
      "Epoch 51/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.0508 - acc: 0.9462\n",
      "Epoch 52/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.0487 - acc: 0.9500\n",
      "Epoch 53/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.0468 - acc: 0.9513\n",
      "Epoch 54/200\n",
      "800/800 [==============================] - 0s 31us/step - loss: 0.0449 - acc: 0.9525\n",
      "Epoch 55/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.0431 - acc: 0.9537\n",
      "Epoch 56/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.0413 - acc: 0.9550\n",
      "Epoch 57/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.0396 - acc: 0.9563\n",
      "Epoch 58/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.0380 - acc: 0.9563\n",
      "Epoch 59/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.0364 - acc: 0.9563\n",
      "Epoch 60/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.0349 - acc: 0.9563\n",
      "Epoch 61/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.0334 - acc: 0.9563\n",
      "Epoch 62/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.0320 - acc: 0.9600\n",
      "Epoch 63/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.0307 - acc: 0.9600\n",
      "Epoch 64/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.0294 - acc: 0.9600\n",
      "Epoch 65/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.0281 - acc: 0.9612\n",
      "Epoch 66/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.0269 - acc: 0.9637\n",
      "Epoch 67/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.0257 - acc: 0.9637\n",
      "Epoch 68/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.0246 - acc: 0.9637\n",
      "Epoch 69/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.0235 - acc: 0.9662\n",
      "Epoch 70/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.0225 - acc: 0.9675\n",
      "Epoch 71/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.0215 - acc: 0.9675\n",
      "Epoch 72/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.0205 - acc: 0.9675\n",
      "Epoch 73/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.0196 - acc: 0.9675\n",
      "Epoch 74/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.0187 - acc: 0.9675\n",
      "Epoch 75/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.0178 - acc: 0.9675\n",
      "Epoch 76/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.0170 - acc: 0.9675\n",
      "Epoch 77/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.0162 - acc: 0.9700\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 29us/step - loss: 0.0154 - acc: 0.9725\n",
      "Epoch 79/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.0147 - acc: 0.9725\n",
      "Epoch 80/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.0140 - acc: 0.9725\n",
      "Epoch 81/200\n",
      "800/800 [==============================] - 0s 31us/step - loss: 0.0133 - acc: 0.9738\n",
      "Epoch 82/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.0126 - acc: 0.9750\n",
      "Epoch 83/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.0120 - acc: 0.9788\n",
      "Epoch 84/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.0114 - acc: 0.9825\n",
      "Epoch 85/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.0108 - acc: 0.9825\n",
      "Epoch 86/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.0103 - acc: 0.9838\n",
      "Epoch 87/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.0097 - acc: 0.9838\n",
      "Epoch 88/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.0092 - acc: 0.9838\n",
      "Epoch 89/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.0087 - acc: 0.9838\n",
      "Epoch 90/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.0083 - acc: 0.9838\n",
      "Epoch 91/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.0078 - acc: 0.9838\n",
      "Epoch 92/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.0074 - acc: 0.9862\n",
      "Epoch 93/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.0070 - acc: 0.9862\n",
      "Epoch 94/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.0066 - acc: 0.9875\n",
      "Epoch 95/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.0062 - acc: 0.9888\n",
      "Epoch 96/200\n",
      "800/800 [==============================] - 0s 31us/step - loss: 0.0059 - acc: 0.9900\n",
      "Epoch 97/200\n",
      "800/800 [==============================] - 0s 32us/step - loss: 0.0055 - acc: 0.9900\n",
      "Epoch 98/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.0052 - acc: 0.9900\n",
      "Epoch 99/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.0049 - acc: 0.9900\n",
      "Epoch 100/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.0046 - acc: 0.9900\n",
      "Epoch 101/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.0043 - acc: 0.9900\n",
      "Epoch 102/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.0040 - acc: 0.9900\n",
      "Epoch 103/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.0038 - acc: 0.9900\n",
      "Epoch 104/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.0036 - acc: 0.9900\n",
      "Epoch 105/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.0033 - acc: 0.9900\n",
      "Epoch 106/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.0031 - acc: 0.9900\n",
      "Epoch 107/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.0029 - acc: 0.9900\n",
      "Epoch 108/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.0027 - acc: 0.9900\n",
      "Epoch 109/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.0025 - acc: 0.9900\n",
      "Epoch 110/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.0024 - acc: 0.9913\n",
      "Epoch 111/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.0022 - acc: 0.9925\n",
      "Epoch 112/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.0020 - acc: 0.9925\n",
      "Epoch 113/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.0019 - acc: 0.9925\n",
      "Epoch 114/200\n",
      "800/800 [==============================] - 0s 32us/step - loss: 0.0018 - acc: 0.9925\n",
      "Epoch 115/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.0016 - acc: 0.9925\n",
      "Epoch 116/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.0015 - acc: 0.9937\n",
      "Epoch 117/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.0014 - acc: 0.9937\n",
      "Epoch 118/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.0013 - acc: 0.9937\n",
      "Epoch 119/200\n",
      "800/800 [==============================] - 0s 33us/step - loss: 0.0012 - acc: 0.9950\n",
      "Epoch 120/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.0011 - acc: 0.9950\n",
      "Epoch 121/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.0010 - acc: 0.9950\n",
      "Epoch 122/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 9.5275e-04 - acc: 0.9950\n",
      "Epoch 123/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 8.7824e-04 - acc: 0.9950\n",
      "Epoch 124/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 8.0860e-04 - acc: 0.9950\n",
      "Epoch 125/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 7.4437e-04 - acc: 0.9962\n",
      "Epoch 126/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 6.8419e-04 - acc: 0.9962\n",
      "Epoch 127/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 6.2880e-04 - acc: 0.9962\n",
      "Epoch 128/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 5.7669e-04 - acc: 0.9962\n",
      "Epoch 129/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 5.2887e-04 - acc: 0.9962\n",
      "Epoch 130/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 4.8464e-04 - acc: 0.9962\n",
      "Epoch 131/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 4.4366e-04 - acc: 0.9962\n",
      "Epoch 132/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 4.0595e-04 - acc: 0.9962\n",
      "Epoch 133/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 3.7133e-04 - acc: 0.9975\n",
      "Epoch 134/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 3.3894e-04 - acc: 0.9975\n",
      "Epoch 135/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 3.0979e-04 - acc: 0.9975\n",
      "Epoch 136/200\n",
      "800/800 [==============================] - 0s 31us/step - loss: 2.8262e-04 - acc: 0.9975\n",
      "Epoch 137/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 2.5778e-04 - acc: 0.9988\n",
      "Epoch 138/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 2.3484e-04 - acc: 0.9988\n",
      "Epoch 139/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 2.1410e-04 - acc: 0.9988\n",
      "Epoch 140/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 1.9517e-04 - acc: 0.9988\n",
      "Epoch 141/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 1.7780e-04 - acc: 0.9988\n",
      "Epoch 142/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 1.6197e-04 - acc: 0.9988\n",
      "Epoch 143/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 1.4766e-04 - acc: 0.9988\n",
      "Epoch 144/200\n",
      "800/800 [==============================] - 0s 31us/step - loss: 1.3461e-04 - acc: 0.9988\n",
      "Epoch 145/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 1.2285e-04 - acc: 0.9988\n",
      "Epoch 146/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 1.1206e-04 - acc: 0.9988\n",
      "Epoch 147/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 1.0239e-04 - acc: 0.9988\n",
      "Epoch 148/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 9.3642e-05 - acc: 0.9988\n",
      "Epoch 149/200\n",
      "800/800 [==============================] - 0s 26us/step - loss: 8.5761e-05 - acc: 0.9988\n",
      "Epoch 150/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 7.8614e-05 - acc: 0.9988\n",
      "Epoch 151/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 7.2181e-05 - acc: 0.9988\n",
      "Epoch 152/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 6.6542e-05 - acc: 0.9988\n",
      "Epoch 153/200\n",
      "800/800 [==============================] - 0s 31us/step - loss: 6.1342e-05 - acc: 0.9988\n",
      "Epoch 154/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 5.6753e-05 - acc: 0.9988\n",
      "Epoch 155/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 5.2587e-05 - acc: 0.9988\n",
      "Epoch 156/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 4.8886e-05 - acc: 0.9988\n",
      "Epoch 157/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 4.5688e-05 - acc: 0.9988\n",
      "Epoch 158/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 4.2734e-05 - acc: 0.9988\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 27us/step - loss: 4.0171e-05 - acc: 0.9988\n",
      "Epoch 160/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 3.7883e-05 - acc: 0.9988\n",
      "Epoch 161/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 3.5879e-05 - acc: 0.9988\n",
      "Epoch 162/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 3.4069e-05 - acc: 0.9988\n",
      "Epoch 163/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 3.2509e-05 - acc: 0.9988\n",
      "Epoch 164/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 3.1118e-05 - acc: 0.9988\n",
      "Epoch 165/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 2.9942e-05 - acc: 0.9988\n",
      "Epoch 166/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 2.8855e-05 - acc: 0.9988\n",
      "Epoch 167/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 2.7901e-05 - acc: 0.9988\n",
      "Epoch 168/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 2.7105e-05 - acc: 0.9988\n",
      "Epoch 169/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 2.6407e-05 - acc: 0.9988\n",
      "Epoch 170/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 2.5799e-05 - acc: 0.9988\n",
      "Epoch 171/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 2.5251e-05 - acc: 0.9988\n",
      "Epoch 172/200\n",
      "800/800 [==============================] - 0s 31us/step - loss: 2.4776e-05 - acc: 0.9988\n",
      "Epoch 173/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 2.4380e-05 - acc: 0.9988\n",
      "Epoch 174/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 2.4063e-05 - acc: 0.9988\n",
      "Epoch 175/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 2.3733e-05 - acc: 0.9988\n",
      "Epoch 176/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 2.3480e-05 - acc: 1.0000\n",
      "Epoch 177/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 2.3280e-05 - acc: 1.0000\n",
      "Epoch 178/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 2.3085e-05 - acc: 1.0000\n",
      "Epoch 179/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 2.2915e-05 - acc: 1.0000\n",
      "Epoch 180/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 2.2779e-05 - acc: 1.0000\n",
      "Epoch 181/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 2.2671e-05 - acc: 1.0000\n",
      "Epoch 182/200\n",
      "800/800 [==============================] - 0s 30us/step - loss: 2.2578e-05 - acc: 1.0000\n",
      "Epoch 183/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 2.2492e-05 - acc: 1.0000\n",
      "Epoch 184/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 2.2425e-05 - acc: 1.0000\n",
      "Epoch 185/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 2.2344e-05 - acc: 1.0000\n",
      "Epoch 186/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 2.2315e-05 - acc: 1.0000\n",
      "Epoch 187/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 2.2285e-05 - acc: 1.0000\n",
      "Epoch 188/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 2.2241e-05 - acc: 1.0000\n",
      "Epoch 189/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 2.2225e-05 - acc: 1.0000\n",
      "Epoch 190/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 2.2186e-05 - acc: 1.0000\n",
      "Epoch 191/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 2.2169e-05 - acc: 1.0000\n",
      "Epoch 192/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 2.2147e-05 - acc: 1.0000\n",
      "Epoch 193/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 2.2137e-05 - acc: 1.0000\n",
      "Epoch 194/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 2.2112e-05 - acc: 1.0000\n",
      "Epoch 195/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 2.2113e-05 - acc: 1.0000\n",
      "Epoch 196/200\n",
      "800/800 [==============================] - 0s 29us/step - loss: 2.2088e-05 - acc: 1.0000\n",
      "Epoch 197/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 2.2097e-05 - acc: 1.0000\n",
      "Epoch 198/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 2.2091e-05 - acc: 1.0000\n",
      "Epoch 199/200\n",
      "800/800 [==============================] - 0s 28us/step - loss: 2.2104e-05 - acc: 1.0000\n",
      "Epoch 200/200\n",
      "800/800 [==============================] - 0s 27us/step - loss: 2.2087e-05 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f70e8622a20>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BOUNCES\n",
    "inputs = Input(shape=(2,))\n",
    "\n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "x = Dense(2)(inputs)\n",
    "\n",
    "predictions = x\n",
    "\n",
    "model_b = Model(inputs=inputs, outputs=predictions)\n",
    "model_b.compile(loss=mean_squared_error,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model_b.summary()\n",
    "\n",
    "df = pd.read_csv('bounces.csv')\n",
    "a = df.to_numpy()\n",
    "a = a.reshape((1000,2,4)) #samples x timesteps x features\n",
    "a = np.delete(a, [1,3], axis=2)\n",
    "train_X = a[:800,0,:]\n",
    "test_X = a[800:,0,:]\n",
    "train_Y = a[:800,1,:]\n",
    "test_Y = a[800:,1,:]\n",
    "model_b.fit(train_X, train_Y, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7f70e03ed518> False\n",
      "<keras.layers.core.Dense object at 0x7f70e03ed4e0> False\n",
      "<keras.engine.input_layer.InputLayer object at 0x7f70f02c0390> False\n",
      "<keras.layers.recurrent.LSTM object at 0x7f70f02c00f0> False\n",
      "<keras.layers.core.Dense object at 0x7f70f0431c88> False\n"
     ]
    }
   ],
   "source": [
    "for m in [model_b, model_ws]:\n",
    "    for l in m.layers:\n",
    "        l.trainable = False\n",
    "        print(l, l.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_rec (InputLayer)          (None, 10, 2)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Model)                 (None, 10, 2)        46          input_rec[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_bnc (InputLayer)          (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 20)           0           model_3[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_4 (Model)                 (None, 2)            6           input_bnc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 22)           0           flatten_1[0][0]                  \n",
      "                                                                 model_4[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 20)           460         concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 512\n",
      "Trainable params: 460\n",
      "Non-trainable params: 52\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.merge import concatenate\n",
    "from keras.layers import Flatten\n",
    "\n",
    "inputs_rec = Input(shape=(10,2), name='input_rec')\n",
    "rec = model_ws(inputs_rec)\n",
    "rec = Flatten()(rec)\n",
    "\n",
    "inputs_bnc = Input(shape=(2,), name='input_bnc')\n",
    "bnc = model_b(inputs_bnc)\n",
    "\n",
    "merge = concatenate([rec, bnc])\n",
    "\n",
    "# x = Dense(22)(merge)\n",
    "x = Dense(20)(merge)\n",
    "\n",
    "model_m = Model(inputs=[inputs_rec, inputs_bnc], outputs=x)\n",
    "model_m.compile(loss=mean_squared_error,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model_m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "800/800 [==============================] - 0s 335us/step - loss: 0.7278 - acc: 0.0038\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 0s 107us/step - loss: 0.4469 - acc: 0.0762\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.2929 - acc: 0.1800\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 0s 112us/step - loss: 0.2028 - acc: 0.1650\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.1453 - acc: 0.1475\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.1061 - acc: 0.1263\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 0s 130us/step - loss: 0.0789 - acc: 0.1037\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 0s 125us/step - loss: 0.0596 - acc: 0.0513\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.0459 - acc: 0.0362\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.0362 - acc: 0.0275\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.0293 - acc: 0.0325\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.0244 - acc: 0.0337\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.0208 - acc: 0.0513\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 0s 121us/step - loss: 0.0181 - acc: 0.0625\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.0161 - acc: 0.0762\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.0145 - acc: 0.0850\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.0131 - acc: 0.0900\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.0120 - acc: 0.0987\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.0111 - acc: 0.1125\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.0102 - acc: 0.1250\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.0095 - acc: 0.1313\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.0089 - acc: 0.1338\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 0s 107us/step - loss: 0.0083 - acc: 0.1387\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.0078 - acc: 0.1487\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.0073 - acc: 0.1575\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 0s 112us/step - loss: 0.0069 - acc: 0.1575\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.0065 - acc: 0.1562\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.0062 - acc: 0.1525\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.0059 - acc: 0.1662\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 0s 112us/step - loss: 0.0056 - acc: 0.1550\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.0053 - acc: 0.1638\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.0051 - acc: 0.1650\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.0049 - acc: 0.1613\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.0047 - acc: 0.1537\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.0046 - acc: 0.1575\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 0s 112us/step - loss: 0.0044 - acc: 0.1550\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.0043 - acc: 0.1487\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.0042 - acc: 0.1475\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 0s 107us/step - loss: 0.0041 - acc: 0.1537\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.0040 - acc: 0.1463\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.0039 - acc: 0.1437\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.0038 - acc: 0.1425\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.0037 - acc: 0.1562\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.0037 - acc: 0.1500\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 0s 112us/step - loss: 0.0036 - acc: 0.1500\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.0035 - acc: 0.1475\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.0035 - acc: 0.1463\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.0034 - acc: 0.1475\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.0034 - acc: 0.1675\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.0034 - acc: 0.1487\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.0033 - acc: 0.1588\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 0s 118us/step - loss: 0.0033 - acc: 0.1625\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.0033 - acc: 0.1512\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.0032 - acc: 0.1525\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.0032 - acc: 0.1437\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.0032 - acc: 0.1588\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.0031 - acc: 0.1638\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.0031 - acc: 0.1575\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.0031 - acc: 0.1562\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 0s 107us/step - loss: 0.0031 - acc: 0.1575\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.0030 - acc: 0.1600\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.0030 - acc: 0.1662\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.0030 - acc: 0.1525\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.0030 - acc: 0.1638\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.0029 - acc: 0.1575\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.0029 - acc: 0.1675\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.0029 - acc: 0.1600\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.0029 - acc: 0.1625\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.0029 - acc: 0.1525\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.0028 - acc: 0.1650\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.0028 - acc: 0.1650\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.0028 - acc: 0.1638\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.0028 - acc: 0.1613\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.0028 - acc: 0.1775\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.0028 - acc: 0.1575\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 0s 107us/step - loss: 0.0027 - acc: 0.1787\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 0s 107us/step - loss: 0.0027 - acc: 0.1638\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.0027 - acc: 0.1837\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 0s 112us/step - loss: 0.0027 - acc: 0.1712\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.0027 - acc: 0.1688\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.0026 - acc: 0.1850\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 0s 107us/step - loss: 0.0026 - acc: 0.1750\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 113us/step - loss: 0.0026 - acc: 0.1775\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.0026 - acc: 0.1700\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.0026 - acc: 0.1650\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.0026 - acc: 0.1950\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.0025 - acc: 0.1825\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.0025 - acc: 0.1813\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.0025 - acc: 0.1750\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.0025 - acc: 0.1837\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.0025 - acc: 0.1900\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.0025 - acc: 0.1925\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 0s 102us/step - loss: 0.0024 - acc: 0.1750\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.0024 - acc: 0.1775\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.0024 - acc: 0.1963\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.0024 - acc: 0.1850\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.0024 - acc: 0.2000\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.0024 - acc: 0.1937\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.0023 - acc: 0.1963\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.0023 - acc: 0.1925\n",
      "(800, 10, 2) (800, 2)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('sim_data_borders.csv')\n",
    "a = df.to_numpy()\n",
    "a = a.reshape((1000,20,4)) #samples x timesteps x features\n",
    "a = np.delete(a, [1,3], axis=2)\n",
    "X = a[:800,:10,:]\n",
    "Y = a[:800,10:,:].reshape(800,20)\n",
    "#[X,X[:,-1,:]]\n",
    "model_m.fit({\n",
    "    'input_rec': X,\n",
    "    'input_bnc': X[:,-1,:]\n",
    "}, Y, epochs=100)\n",
    "\n",
    "# model.fit([X,X[:,-1,:]], Y, epochs=100)\n",
    "print(X.shape,X[:,-1,:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.047914549817227946"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = a[800:,10:,:].reshape(200,20)\n",
    "test_X = a[800:,:10,:]\n",
    "preds = model_m.predict({\n",
    "    'input_rec': test_X,\n",
    "    'input_bnc': test_X[:,-1,:]\n",
    "})\n",
    "rmse(actual, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and loading a Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06516839669886042"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = a[800:,10:,:]\n",
    "preds = model.predict(a[800:,:10,:])\n",
    "\n",
    "rmse(actual, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7f9bd289c160>\n",
      "<keras.layers.recurrent.LSTM object at 0x7f9bd289c278>\n",
      "<keras.layers.core.Dense object at 0x7f9bd289c860>\n"
     ]
    }
   ],
   "source": [
    "for layer in loaded_model.layers:\n",
    "    print(layer) #.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_4:0' shape=(?, 10, 2) dtype=float32>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
